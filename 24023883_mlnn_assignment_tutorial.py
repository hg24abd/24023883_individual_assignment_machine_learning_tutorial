# -*- coding: utf-8 -*-
"""24023883_mlnn_assignment_tutorial.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1toVTPcDUarh5SM3pSCS89v4l_zCoQdnV
"""

# 2.4 Visualizing the STL-10 Dataset Step-by-Step
# First, let's load and visualize STL-10:

import numpy as np

import torchvision

import matplotlib.pyplot as plt

from torchvision.datasets import STL10



# Load STL-10 dataset

dataset = STL10(root="./data", split="train", download=True)

# Now, let's display 10 random images:

fig, axes = plt.subplots(2, 5, figsize=(10, 5))

for i, ax in enumerate(axes.flat):

    img, label = dataset[i]

    ax.imshow(np.array(img).transpose(1, 2, 0))

    ax.set_title(f"Class: {dataset.classes[label]}")

    ax.axis("off")

plt.show()

# To better understand the dataset, we visualize sample images:

import numpy as np
import torchvision
import matplotlib.pyplot as plt
from torchvision.datasets import STL10

dataset = STL10(root="./data", split="train", download=True)
fig, axes = plt.subplots(2, 5, figsize=(10, 5))
for i, ax in enumerate(axes.flat):
    img, label = dataset[i]
    ax.imshow(np.array(img).transpose(1, 2, 0))
    ax.set_title(f"Class: {dataset.classes[label]}")
    ax.axis("off")
plt.show()

# Example Code: Data Augmentation for Contrastive Learning

from torchvision import transforms

# Define transformations used in SimCLR
simclr_transforms = transforms.Compose([
    transforms.RandomResizedCrop(96),
    transforms.RandomHorizontalFlip(),
    transforms.ColorJitter(0.4, 0.4, 0.4, 0.4),
    transforms.RandomGrayscale(p=0.2),
    transforms.ToTensor()
])

# Step 1: Load Data with Augmentations

from torch.utils.data import DataLoader

train_loader = DataLoader(STL10(root="./data", split="train", transform=simclr_transforms, download=True), batch_size=256, shuffle=True)

#Step 2: Define a Feature Extractor (ResNet-18)

import torch import torchvision.models as models

class SimCLRFeatureExtractor(torch.nn.Module): def init(self): super(SimCLRFeatureExtractor, self).init() self.encoder = models.resnet18(pretrained=True) self.encoder.fc = torch.nn.Identity() # Remove classification head

def forward(self, x):
    return self.encoder(x)

# Step 3: Implementing the Projection Head

class ProjectionHead(torch.nn.Module): def init(self, input_dim=512, output_dim=128): super(ProjectionHead, self).init() self.fc1 = torch.nn.Linear(input_dim, 256) self.fc2 = torch.nn.Linear(256, output_dim)

def forward(self, x):
    x = torch.nn.functional.relu(self.fc1(x))
    x = self.fc2(x)
    return x

from torchvision import transforms

simclr_transforms = transforms.Compose([
    transforms.RandomResizedCrop(96),
    transforms.RandomHorizontalFlip(),
    transforms.ColorJitter(0.4, 0.4, 0.4, 0.4),
    transforms.RandomGrayscale(p=0.2),
    transforms.ToTensor()
])

# This ensures strong augmentation to generate positive pairs for contrastive learning.

